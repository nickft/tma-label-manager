[globals]
##
## These parameters, beside the occasional conversion between seconds and microseconds for 
## the sake of usability, mirror the ones defined for Tstat in param.h
## 

#########################################################
##                                                     ##
## Part 1. System Dimensioning                         ##
##                                                     ##
#########################################################

## MAX_TCP_PAIRS - Maximum number of concurrent TCP connection tracked by Tstat. 
##                 The higher the link speed, the larger this number, considering the memory footprint
##                 and the concurrent MAX_UDP_PAIRS value. 
## E.g. with MAX_TCP_PAIRS = 180000 we suppose no more than 180000 flows are simultaneously active
##                 (taking the effect of TCP_SINGLETON_TIME and TCP_IDLE_TIME in consideration), value
##                 that might be sufficient for a mildly loaded probe on a 2Gbps link 
# max_tcp_pairs = 180000

## MAX_UDP_PAIRS - Maximum number of concurrent UDP connection tracked by Tstat. 
##                 The higher the link speed, the larger this number, considering the memory footprint
##                 and the concurrent MAX_TCP_PAIRS value. 
## E.g. with MAX_UDP_PAIRS = 360000 we suppose no more than 360000 flows are simultaneously active
##                 (taking the effect of UDP_SINGLETON_TIME and UDP_IDLE_TIME in consideration), value
##                 that might be sufficient for a mildly loaded probe on a 2Gbps link 
# max_udp_pairs = 360000

## HASH_TABLE_SIZE - Connection records are stored in a hash table. 
##                   Buckets are linked lists sorted by most recent access.
##                   It should be an odd (possibly prime) value, larger than MAX_TCP_PAIRS and MAX_UDP_PAIRS,
##                   to better distribute the entries among the buckets
# hash_table_size = 2000003

## ------------------------------------------------------

#########################################################
##                                                     ##
## Part 2. System Performance                          ##
##                                                     ##
#########################################################

## TCP_IDLE_TIME - Minimum timeout (in seconds) to consider a TCP flow closed 
##                 if no segments are observed since TCP_IDLE_TIME
##                 (it's internally converted to microseconds)
##                 It's a minimum value: the actual time depends on GC_CYCLE_TIME
## E.g. for 5min TCP_IDLE_TIME = 300 
# tcp_idle_time = 300.0

## UDP_IDLE_TIME - Minimum timeout (in seconds) to consider a UDP flow closed 
##                 if no segments are observed since UDP_IDLE_TIME
##                 (it's internally converted to microseconds)
##                 It's a minimum value: the actual time depends on GC_CYCLE_TIME
## E.g. for 3min and 20s UDP_IDLE_TIME = 200 
# udp_idle_time = 200.0

## TCP_SINGLETON_TIME - Minimum timeout (in seconds) to consider a TCP flow closed  
##                 if no segments are observed for TCP_SINGLETON_TIME 
##                 after the initial SYN segment 
##                 (it's internally converted to microseconds)
##                 It's a minimum value: the actual time depends on GC_CYCLE_TIME
## E.g. for 10s TCP_SINGLETON_TIME = 10.0 
# tcp_singleton_time = 10.0

## UDP_SINGLETON_TIME - Minimum timeout (in seconds) to consider an UDP flow closed  
##                 if no segments are observed for UDP_SINGLETON_TIME 
##                 after the initial UDP segment 
##                 (it's internally converted to microseconds)
##                 It's a minimum value: the actual time depends on GC_CYCLE_TIME
## E.g. for 10s UDP_SINGLETON_TIME = 10.0 
# udp_singleton_time = 10.0

## GC_CYCLE_TIME - Defines how often garbage collection scans the whole flow table.
##                 It is the time (in seconds) between two checks of the same flow table 
##                 entry. Historically, it is normally set to half TCP_SINGLETON_TIME,
##                 supposing that TCP_SINGLETON_TIME is smaller than TCP_IDLE_TIME.
##                 (it's internally named GARBAGE_PERIOD and converted to microseconds)
##                 Since Tstat checks are asyncronous, the actual timeouts are usually
##                 uniformly distributed in [MIN_TIMOUT, MIN_TIMEOUT+GC_CYCLE_TIME], with 
##                 a small probability for larger values.
## E.g. for 5s GC_CYCLE_TIME = 5.0
# gc_cycle_time = 5.0

## GC_SPLIT_RATIO - Define granularity of garbage collection splitting. 
##                 The flow table is not scanned in one time, but the workload 
##                 is done in GC_SPLIT_RATIO times
##                 IMPORTANT: it must be a divisor of MAX_TCP_PAIRS, MAX_UDP_PAIRS, and possibly
##                 GC_CYCLE_TIME (when represented as an integer number of microseconds)
## E.g. GC_SPLIT_RATIO = 10000 divides the garbage collection cycle in 10000 parts, checking each time
##                 MAX_TCP_PAIRS/10000 entries in the the TCP flow table and MAX_UDP_PAIRS/10000 entries
##                 in the UDP flow table.
# gc_split_ratio = 10000

## ------------------------------------------------------

#########################################################
##                                                     ##
## Part 3. Additional Data Structures                  ##
##                                                     ##
## Change only if the default values are too small     ##
##                                                     ##
#########################################################

## MAX_ADX_SLOTS - Size of the hash for the IP addresses hit counter. 
##                 As for most hashes, it should be an odd number.
# max_adx_slots = 70001

## Maximum number of IPv4 and IPv6 network addresses defining specific host 
## classifications. IPv4 and IPv6 are stored in separate structures, so the
## actual cumulative size is twice the defined size. 
## In parenthesis the associated command line option
## MAX_INTERNAL_HOSTS - Networks to be considered "internal" in logs and RRD (-N) 
## MAX_CLOUD_HOSTS    - Subset of networks (named "cloud") distinguished in some RRDs (-C)
## MAX_CRYPTO_HOSTS   - Networks whose IPs must be encrypted by the CPAn algorithm (-Y)
## MAX_WHITE_HOSTS    - Networks whose IPs are not encrypted by the CPAn algorithm (-W)
# max_internal_hosts = 100
# max_cloud_hosts    = 100
# max_crypto_hosts   = 40
# max_white_hosts    = 100

## MAX_INTERNAL_ETHERS - Maximum number of Ethernet addresses identified as "sources" 
##                       of internal traffic (-M)
# max_internal_ethers = 20

## MAX_CRYPTO_CACHE_SIZE
## To reduce the memory footprint of long running Tstat instances, the encrypted IPv4 
## addresses are stored in a LRU cache with size MAX_CRYPTO_CACHE_SIZE 
# max_crypto_cache_size = 130000

## DNS_CACHE_SIZE - Size of the IPv4 DNS cache for the DNhunter algorithm
##                  DNS_CACHE_SIZE = 100000 can be ok for smaller probes, storing
##                  the entries for about 30m. On large probes it should be larger
##                  (e.g 500000 or more)
# dns_cache_size = 100000

## DNS_CACHE_SIZE_IPV6 - Size of the IPv6 DNS cache for the DNhunter algorithm
##                  Default value is DNS_CACHE_SIZE_IPV6 = 1000. 
##                  It might be small, but currently IPv6 traffic and DNS queries 
##                  are very limited. Increase if IPv6 is significant in your environment
# dns_cache_size_ipv6 = 1000

## ------------------------------------------------------

#########################################################
##                                                     ##
## Part 4. Logs and measures                           ##
##                                                     ##
## Change  to tailor the logging activity              ##
##                                                     ##
#########################################################

## RUNTIME_CONFIG_IDLE and RUNTIME_MTIME_COUNTER
##                 They are used to define the amount of time to wait before re-loading 'runtime.conf'
##                 RUNTIME_CONFIG_IDLE is the time (in seconds) between ckecks of 'runtime.conf' 
##                 (or whatever is the -T argument). If the file has been modified (i.e. its mtime
##                 changed), we check it stays unmodified for at least RUNTIME_MTIME_COUNTER 
##                 intervals, and then we parse its content to update the runtime configuration.
## E.g. RUNTIME_CONFIG_IDLE = 21.0 and RUNTIME_MTIME_COUNTER = 3 means that we identify the file as 
##                 modified 21 seconds after its latest modification, and we actually wait for 63 (21*3)
##                 seconds before parsing the content and change Tstat runtime behavior.
##                 WARNING: due to the way the log directories are managed, the overall time 
##                 should be larger than 60 seconds, otherwise any change in runtime.conf that
##                 triggers the reopening of the log files might provoke the deletion of previous logs.
# runtime_config_idle = 21.0
# runtime_mtime_counter = 3

## MAX_TIME_STEP - Histograms will be saved every MAX_TIME_STEP seconds.
##                 Please, note that changing this may affect the RRD definition as well. 
##                 Updates for both Histograms and RRDs are performed every MAX_TIME_STEP.
##                 It's also the base unit for the creation and the rotation of the log files.
## E.g. for 5m max_time_step = 300.0 
# max_time_step = 300.0

## DIRS - Controls the frequency at which a new log directory is created.
##        In particular, a new directory tree is created every DIRS*MAX_TIME_STEP seconds
##        E.g. MAX_TIME_STEP = 300.0 and DIRS = 12 -> a new directory tree every hour
##             MAX_TIME_STEP = 300.0 and DIRS = 1  -> a new directory tree every 5 minutes
# dirs = 12

## RATE_SAMPLING
## Specific flow statistics (bytes, average bitrate) are computed every RATE_SAMPLING seconds 
## for video flows. These statistics are available in the log_video_advanced set.
# rate_sampling = 1.0

## ------------------------------------------------------

#########################################################
##                                                     ##
## Part 5. Advanced parameters                         ##
##                                                     ##
## Very specific, change at your risk                  ##
##                                                     ##
#########################################################


## MAX_SEG_PER_QUAD
## Maximum number of segment recorded for each quadrant of a flow;
## setting this too small will affect the rexmit statistics, but leaving it
## unlimited will pose a serious scalability problem, as the ordered list
## of segments may grow too large, consuming too much memory and time when
## looking for a segment. Probably should never be necessary to store more
## than a number of segments larger than one hundred, since the
## sliding window of TCP is usually much smaller than that (except if you
## use TCP versions which allow very large windows ...)
## E.g. MAX_SEG_PER_QUAD 0  to track all segments
##      MAX_SEG_PER_QUAD 10 for light segment tracking at high load
##      MAX_SEG_PER_QUAD 100 deep segment tracking, suitable for light load
# max_seg_per_quad = 100

## LIST_SEARCH_DEPT - Max depth of the linear search in the previous TCP_PAIRS and UDP_PAIRS vectors.
##                 The larger the value, the smaller the probability that a flow having a clash in the 
##                 hashing function is discarded due to limited space in the flow vectors.
##                 If memory is not an issue, it's probably better to increase MAX_TCP_PAIRS and/or
##                 MAX_UDP_PAIRS than changing LIST_SEARCH_DEPT. 
# list_search_dept = 200

## To detect encrypted (BitTorrent) flows, a simple check on the information entropy of the
## payload is computed. 
## Entropy is computed on nibbles (4 bits), so it is in the [0.0,4.0] interval.
## ENTROPY_SAMPLE - Number of bytes in each packet payload used to compute the nibble entropy
##                  Up to 4 packets in the flow are considered, and up to ENTROPY_SAMPLE bytes 
##                  are checked in each packet.
## ENTROPY_THRESHOLD  - Threshold for the nibble entropy above which we consider the content
##                  random. Empirically tested that nibble entropy over about 100 random 
##                  samples is larger than 3.7 with 99% probability
# entropy_sample = 60
# entropy_threshold = 3.7

## MIN_DELTA_T_UDP_DUP_PKT and MIN_DELTA_T_TCP_DUP_PKT
##                 These parameters control the heuristic to detect duplicate TCP/UDP packets
##                 May be useful when the original trace (or the live feed) has some NETWORK dups
##                 (possibly due to the configuration of the routers span-ports)
##                 Each packets is compared with the previous one (in the same TCP/UDP flow)
##                 and discarded if it has:
##                   - same IP_ID
##                   - same TCP/UDP checksum
##                   - interarrival time smaller than MIN_DELTA_T_XXX_DUP_PKT
##                   - same IP length
##                 Both parameters are in microseconds.
# min_delta_t_tcp_dup_pkt = 2000.0
# min_delta_t_udp_dup_pkt = 1000.0
